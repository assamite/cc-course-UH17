
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Week 2 - Fictional Fact Generation &#8212; CC-Course-UH 2017 0.1a documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.1a',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="week-2-fictional-fact-generation">
<h1>Week 2 - Fictional Fact Generation<a class="headerlink" href="#week-2-fictional-fact-generation" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">1.11.17 These assignments are still subject to change.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>The paper <a class="reference external" href="http://mark.granroth-wilding.co.uk/files/iccc2014.pdf">Baseline Methods for Automated Fictional Ideation</a>
describes some simple methods for generating fictional ideas. One of them, described in the section
<em>Fictional Ideation using ReVerb</em>, uses general-knowledge facts extracted from text with information extraction (IE)
techniques, and manipulates the facts to produce potentially interesting or amusing fictional ideas.</p>
<p>The method is simple and in itself barely qualifies as a creative system, being guided only by some simple statistics
and having no further representation at all of the meaning or value of the results. However, it can form one
generative component of a creative system and it demonstrates how NLP can be used to provide a knowledge resource
for creative processes.</p>
<p>In this week’s exercises, you will implement the generative method. Instead of applying IE tools yourself, you
will use the output of a fairly recent system and write the code to manipulate facts to produce fictions.</p>
</div>
<div class="section" id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h2>
<p>We will use facts output in the form of <em>relation triples</em> by the <a class="reference external" href="http://reverb.cs.washington.edu/">ReVerb</a>
system. A large set of facts, produced by running the system over a large text corpus, is available to
<a class="reference external" href="http://reverb.cs.washington.edu/reverb_clueweb_tuples-1.1.txt.gz">download</a>. However, it is large enough
to prohibit simply loading the whole set into memory and computing the statistics we need.</p>
<p>To simplify this, you can
<a class="reference external" href="https://www.cs.helsinki.fi/u/magranro/cc2017/reverb.txt">download a smaller, filtered set here</a>.
This includes facts that appear to
be somewhat related to terms found in <em>Alice’s Adventures in Wonderland</em> (the text you
used last week).</p>
<p>The Python module <a class="reference external" href="https://github.com/assamite/cc-course-UH17/blob/master/week2/factgen.py">factgen</a>
contains some utilities for handling this data. Download it and put it in the same directory as your code,
so you can easily import it:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="kn">import</span> <span class="nn">factgen</span>
</pre></div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Write code to load the filtered set of ReVerb triples. You can use the <code class="docutils literal"><span class="pre">read_triples()</span></code> function:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">all_triples</span> <span class="o">=</span> <span class="n">factgen</span><span class="o">.</span><span class="n">read_triples</span><span class="p">(</span><span class="s2">&quot;reverb.txt&quot;</span><span class="p">,</span> <span class="n">min_attested</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>See the docstring for the meaning of <code class="docutils literal"><span class="pre">min_attested</span></code>. You may want to adjust this parameter later on
and see what effect it has.</p>
<p>Build a list of all of the <em>entities</em> (the left-hand side or right-hand side of the triples).
You can use the <code class="docutils literal"><span class="pre">collect_entities()</span></code> function to help with this.</p>
<p>Prepare a list of some entities that you will use as input to the generation process. You may do
this at this stage by manually selecting some entities of interest from those in the triples, or
by programmatically randomly choosing some.</p>
<p>Print out the facts about these entities, so you can get an idea of what your system will be starting
from.</p>
</li>
<li><p class="first"><strong>RETURN</strong> <em>(Code)</em> Implement the fact-manipulation technique described in
<a class="reference external" href="http://mark.granroth-wilding.co.uk/files/iccc2014.pdf">‘Fictional Ideation using ReVerb’ in the paper</a>,
and introduced in Wednesday’s lecture.</p>
<p>You will need to write code to estimate the probability of a relation <em>r</em> given a LHS entity <em>X</em> (<em>p(r | X)</em>)
and the probability of a RHS entity <em>Y</em> given a relation (<em>p(Y |&nbsp;r)</em>). Then you must compute these
quantities for all possible relations and RHS entities, starting from one of your query terms on the LHS.</p>
<p>Write a function <code class="docutils literal"><span class="pre">generate_from_lhs(lhs,</span> <span class="pre">all_triples)</span></code> that takes the LHS entity <code class="docutils literal"><span class="pre">lhs</span></code> and a list of
triples, as read in above, <code class="docutils literal"><span class="pre">all_triples</span></code> and returns a list of new, generated triples ordered by descending
score, together with their scores:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">rhs_replacements</span> <span class="o">=</span> <span class="n">generate_from_lhs</span><span class="p">(</span><span class="n">QUERY_TERM</span><span class="p">,</span> <span class="n">all_triples</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Top scoring made-up </span><span class="si">{}</span><span class="s2">-related facts:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="n">QUERY_TERM</span><span class="p">,</span>
    <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">  (</span><span class="si">{:.3f}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span> <span class="ow">in</span> <span class="n">rhs_replacements</span><span class="p">[:</span><span class="mi">30</span><span class="p">])</span>
<span class="p">))</span>

<span class="n">Top</span> <span class="n">scoring</span> <span class="n">made</span><span class="o">-</span><span class="n">up</span> <span class="n">dinner</span><span class="o">-</span><span class="n">related</span> <span class="n">facts</span><span class="p">:</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">usually</span> <span class="n">consists</span> <span class="n">of</span><span class="p">,</span> <span class="n">gift</span> <span class="n">certificates</span>  <span class="p">(</span><span class="mf">0.100</span><span class="p">)</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">consists</span> <span class="n">of</span><span class="p">,</span> <span class="n">grass</span>  <span class="p">(</span><span class="mf">0.067</span><span class="p">)</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">consists</span> <span class="n">of</span><span class="p">,</span> <span class="n">nave</span>  <span class="p">(</span><span class="mf">0.067</span><span class="p">)</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">consisted</span> <span class="n">of</span><span class="p">,</span> <span class="n">eggs</span>  <span class="p">(</span><span class="mf">0.050</span><span class="p">)</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">consisted</span> <span class="n">of</span><span class="p">,</span> <span class="n">soup</span>  <span class="p">(</span><span class="mf">0.050</span><span class="p">)</span>
<span class="n">dinner</span><span class="p">,</span> <span class="n">consisted</span> <span class="n">of</span><span class="p">,</span> <span class="n">cake</span>  <span class="p">(</span><span class="mf">0.050</span><span class="p">)</span>
</pre></div>
</div>
<p><em>(Optional)</em> Also implement the corresponding function <code class="docutils literal"><span class="pre">generate_from_rhs(rhs,</span> <span class="pre">all_triples)</span></code> to generate
triples given a RHS entity.</p>
</li>
<li><p class="first"><strong>RETURN</strong> <em>(Text)</em> Take a look at the output of your generator, given several different queries as input.
If all has gone well, you should find that some of the imaginary facts it outputs are at least a bit interesting
or amusing. Others will be nonsensical or uninteresting (e.g. <em>dinner, consisted of, soup</em>).</p>
<p>Why is this the case? How could this basic method be extended to increase the proportion of coherent and
valuable outputs? Suggest some practical techniques that could be applied to achieve this.</p>
<p>Focus in particular on simple methods that you would expect to get maximal improvements with minimal effort.
If we were able to do reliable commonsense reasoning with broad-domain world knowledge, we could rule out
<em>dinner, consisted of, soup</em> on the basis that it dinner often <em>does</em> consist of soup, but how can we perform
(or approximate) this reasoning automatically using existing techniques or technologies?</p>
<p><strong>You do not have to implement the methods!</strong> By all means, do if you want and I’d love to see the result, but
it’s not required!</p>
</li>
<li><p class="first"><strong>RETURN</strong> <em>(Code)</em> Return to your code from last week’s exercises, where you trained a Markov model
on the text of <em>Alice’s Adventures in Wonderland</em>.</p>
<p>Alter your function <code class="docutils literal"><span class="pre">markov_chain</span></code> to accept an optional parameter <code class="docutils literal"><span class="pre">order</span></code> which
specifies the order of the Markov chain to be created.</p>
<p>That is, with <code class="docutils literal"><span class="pre">order=2</span></code> a state contains two successive tokens from the same sentence.</p>
</li>
<li><p class="first"><strong>RETURN</strong> <em>(Code)</em> Create a new version of your function <code class="docutils literal"><span class="pre">generate</span></code>,
<code class="docutils literal"><span class="pre">generate2(probs1,</span> <span class="pre">probs2,</span> <span class="pre">length=10,</span> <span class="pre">start=None)</span></code>. <code class="docutils literal"><span class="pre">probs1</span></code> and <code class="docutils literal"><span class="pre">probs2</span></code> are now expected to be the
state transition distributions for an order-1 and an order-2 Markov model, respectively.</p>
<p>This function should generate from the Markov model as before, except that, if it encounters a context
of two words that does not exist in the order-2 model’s distribution, it uses the order-1 model instead,
treating just the single latest word as context.</p>
<p>This is a form of a commonly used technique when working with Markov models, known as <em>backoff</em>.</p>
</li>
<li><p class="first"><strong>RETURN</strong> <em>(Output)</em>
<a class="reference external" href="https://www.cs.helsinki.fi/u/magranro/cc2017/alice_with_triples.txt">Download this text file</a>
and use it to train a new Markov model on this text, performing all the same preprocessing as you did before.
It contains the full text of <em>Alice’s Adventures in Wonderland</em>, plus text covering all of the words used
in the ReVerb triples at least once (provided you set <code class="docutils literal"><span class="pre">min_attested</span></code> to <code class="docutils literal"><span class="pre">2</span></code> or more).</p>
<p>Use your function <code class="docutils literal"><span class="pre">generate_from_lhs</span></code> (together with <code class="docutils literal"><span class="pre">generate_from_rhs</span></code>, if you implemented it)
to produce a small number of high-scoring output triples as before. Put together the three parts of
each triple and split the words to produce a (roughly) tokenized sentence <code class="docutils literal"><span class="pre">s</span></code>.</p>
<p>Now use <code class="docutils literal"><span class="pre">generate2</span></code>, with the transition probabilities trained on <code class="docutils literal"><span class="pre">alice_with_triples.txt</span></code>, using the
last two words of <code class="docutils literal"><span class="pre">s</span></code> as a start state. Add the generated words onto <code class="docutils literal"><span class="pre">s</span></code> to produce a longer sentence.</p>
<p>You have now combined two generative methods in order to get an initial (sometimes) interesting seed from
one and continue the story with another. These components could, of course, be combined with many other
components to generate, modify, filter, expand, etc.</p>
</li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">CC-Course-UH 2017</a></h1>








<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="preliminaries.html">1. Preliminaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="course_format.html">2. Course Format</a></li>
<li class="toctree-l1"><a class="reference internal" href="linguistic_creativity.html">3. Linguistic Creativity</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignments.html">4. Assignments</a></li>
<li class="toctree-l1"><a class="reference internal" href="zz_references.html">5. References</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Simo Linkola.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/ex_fact_generation.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>